{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583bcbed",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db92976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import dgl\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from dgl.nn import GATConv\n",
    "from model import *\n",
    "from utils import *\n",
    "from maml import *\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db291dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import yaml\n",
    "import time\n",
    "from datasets import traffic_dataset\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581296d9",
   "metadata": {},
   "source": [
    "# Configure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c3a1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "'''----Multi-Type Feature Fusion for User Representation----'''\n",
    "num_features = 1\n",
    "num_hidden = 64\n",
    "s_layers = 2\n",
    "l_layers = 3\n",
    "kernel_size_s = 3\n",
    "kernel_size_l = 7\n",
    "dropout = 0.2\n",
    "sigma = 1.0\n",
    "\n",
    "\n",
    "'''----Multi-granularity Graph Alignment with Feature Fusion----'''\n",
    "multi_view_len = 2\n",
    "num_gat_layers = 3\n",
    "in_dim = 64   # 输入特征维度\n",
    "hidden_dim = 32\n",
    "emb_dim = 8\n",
    "num_heads = 2\n",
    "emb_epoch = 50\n",
    "\n",
    "\n",
    "'''----Multi-City Knowledge Transfer Based on Meta-Learning----'''\n",
    "source_epochs = 50\n",
    "target_epochs = 120\n",
    "source_lr = 0.01\n",
    "model_args['meta_lr'] = 0.001\n",
    "wd_ft = 0.005\n",
    "meta_dim = 16\n",
    "target_days = 3\n",
    "loss_lambda = 1.5\n",
    "model = 'GRU'\n",
    "\n",
    "\n",
    "'''----Load config file----'''\n",
    "config_filename = 'config.yaml'\n",
    "test_dataset = 'shanghai'\n",
    "with open(config_filename) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "data_args, task_args, model_args = config['data'], config['task'], config['model']\n",
    "source_dataset = traffic_dataset(data_args, task_args, \"source\", test_data=test_dataset)\n",
    "mean = config['data'][test_dataset]['mean']\n",
    "std = config['data'][test_dataset]['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2a779",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7015867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data:\n",
    "'''\n",
    "time_series_np         # (num_users=node_nums, sequence_length)\n",
    "dynamic_attributes     # (num_users=node_nums, num_dynamic_attributes=4, dynamic_attributes_dim=64)\n",
    "static_attributes      # (num_users=node_nums, static_attributes_dim=10)\n",
    "source_graphs1 : beijing\n",
    "source_graphs2 : shanghai\n",
    "target_graphs  : zhengzhou\n",
    "'''\n",
    "# 创建自定义数据集\n",
    "my_dataset = MyDataset(train_data, dynamic_attributes, static_attributes)\n",
    "# 使用自定义数据集创建 DataLoader\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(my_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48467b93",
   "metadata": {},
   "source": [
    "# Load Multi-Type Feature Fusion for User Representatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa9c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "time_series_np_temp = scaler.fit_transform(time_series_np)\n",
    "train_data = torch.from_numpy(time_series_np_temp.reshape(time_series_np_temp.shape[0], 1, time_series_np_temp.shape[1]).astype(np.float32))\n",
    "train_data = torch.Tensor(train_data).to(device)\n",
    "                              \n",
    "encoder = DemandEncoder(time_series_np.shape[0], num_features, num_hidden, s_layers, l_layers, kernel_size_s, kernel_size_l, dropout).to(device)\n",
    "decoder = DemandDecoder(time_series_np.shape[0], num_features, num_hidden, s_layers, l_layers, kernel_size_s, kernel_size_l, dropout).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.01)\n",
    "# Create an instance of the multi-type attributes co-encoder\n",
    "co_encoder = MultiTypeAttributesCoEncoder(dynamic_attributes_dim=dynamic_attributes_dim, static_attributes_dim=static_attributes_dim, num_dynamic_attributes=num_dynamic_attributes, num_industries=num_industries).to(device)\n",
    "seq2gauss = seq2gauss_model(num_hidden, num_hidden, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2be4d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time-series pre_training\n",
    "def time_feat_pre_train(encoder, decoder, train_loader, optimizer):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (data, dynamic_attribute, static_attribute) in enumerate(train_loader):\n",
    "        z = encoder(data)\n",
    "        x_hat = decoder(z)\n",
    "        loss = criterion(x_hat, data)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f89ce362",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(pre_times_epoch)):\n",
    "    time_feat_train_loss = time_feat_pre_train(encoder, decoder, data_loader, optimizer)\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {time_feat_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab7b1a",
   "metadata": {},
   "source": [
    "# Load Multi-granularity Graph Alignment with Feature Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0021285",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvgat = MVGAT(multi_view_len, num_gat_layers, in_dim, hidden_dim, emb_dim, num_heads, True).to(device)\n",
    "fusion = FusionModule(multi_view_len, emb_dim, 0.8).to(device)\n",
    "source_agg_graph1 = Agg_Graph(source_graphs[0].num_nodes(), np.load('./data/beijing/matrix.npy').shape[0], emb_dim).to(device)\n",
    "source_agg_graph2 = Agg_Graph(source_graphs[0].num_nodes(), np.load('./data/shanghai/matrix.npy').shape[0], emb_dim).to(device)\n",
    "target_agg_graph = Agg_Graph(target_graphs[0].num_nodes(), np.load('./data/shanghai/matrix.npy').shape[0], emb_dim).to(device)\n",
    "emb_param_list = list(encoder.parameters()) + list(decoder.parameters()) + list(seq2gauss.parameters()) + list(mvgat.parameters()) + list(fusion.parameters()) + list(source_agg_graph1.parameters()) + list(source_agg_graph2.parameters()) + list(target_agg_graph.parameters())\n",
    "emb_optimizer = optim.Adam(emb_param_list, lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2b419ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_lambda = 0.01  # Decay rate hyperparameter\n",
    "windows_size = 30  # Starting time step for aggregation\n",
    "source_graph_input1 = [aggregate_dynamic_graphs(source_graphs1, decay_lambda, windows_size).to(device), source_graph_peer.to(device)]\n",
    "source_graph_input2 = [aggregate_dynamic_graphs(source_graphs2, decay_lambda, windows_size), source_graph_peer.to(device)]\n",
    "target_graph_input = [target_graphs[0].to(device), target_graph_peer.to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46d1db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(emb_epoch)):\n",
    "    node_embedding_list = []\n",
    "    for i, (data, dynamic_attribute, static_attribute) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        z = encoder(data)\n",
    "        # Compute the user attribute encodings\n",
    "        attribute_encodings = co_encoder(dynamic_attribute, static_attribute)\n",
    "        node_embedding = seq2gauss(z, attribute_encodings)\n",
    "        node_embedding_list.append(node_embedding.cpu().detach())\n",
    "    node_embedding = node_embedding_list[0]\n",
    "    for i in node_embedding_list[1:]:\n",
    "        node_embedding = torch.concat((node_embedding, i), dim=0)\n",
    "    source_graph_feat = node_embedding[0:3881].to(device)\n",
    "    target_graph_feat = node_embedding[3881:].to(device)\n",
    "    source_views_city1 = mvgat(source_graph_input1, source_graph_feat)\n",
    "    source_views_city2 = mvgat(source_graph_input2, source_graph_feat)\n",
    "    target_views = mvgat(target_graph_input, target_graph_feat)\n",
    "    source_fused_emb1, source_embs = fusion(source_views_city1)  # 这里得到了每个节点的embedding表示，以及multi-view融合后的embedding表示\n",
    "    source_fused_emb2, source_embs = fusion(source_views_city2)  # 这里得到了每个节点的embedding表示，以及multi-view融合后的embedding表示\n",
    "    \n",
    "    target_fused_emb, target_embs = fusion(target_views)  # 这里得到了每个节点的embedding表示，以及multi-view融合后的embedding表示\n",
    "    source_zone_embedding1, source_matrix1 = source_agg_graph1(source_fused_emb1)\n",
    "    source_zone_embedding2, source_matrix2 = source_agg_graph2(source_fused_emb2)\n",
    "#         print(source_matrix)\n",
    "    target_zone_embedding1, target_matrix = target_agg_graph(target_fused_emb)\n",
    "    source_fused_emb =torch.concat((source_fused_emb1, source_fused_emb2), dim=0)\n",
    "    mmdloss = mmd_loss(source_fused_emb, target_fused_emb,sigma)\n",
    "    entropy_loss = nn.CrossEntropyLoss()\n",
    "    entropy_loss = entropy_loss(source_matrix1, source_matrix1) + entropy_loss(source_matrix2, source_matrix2) + entropy_loss(target_matrix, target_matrix)\n",
    "    loss_global = mmdloss + 0.01 * entropy_loss\n",
    "    emb_optimizer.zero_grad()\n",
    "    loss = loss_global\n",
    "#     print(loss)\n",
    "    loss.backward()  \n",
    "    emb_optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc072860",
   "metadata": {},
   "source": [
    "# Training and test (Multi-City Knowledge Transfer Based on Meta-Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9862ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_STMAML = STMAML(data_args, task_args, model_args, emb_param_list, model=model).to(device)\n",
    "source_param_list = emb_param_list + list(model_STMAML.parameters())\n",
    "source_optimizer = optim.Adam(emb_param_list, lr=source_lr, weight_decay=wd_ft)\n",
    "    \n",
    "for epoch in tqdm(range(source_epochs)):\n",
    "    node_embedding_list = []\n",
    "    for i, (data, dynamic_attribute, static_attribute) in enumerate(data_loader):\n",
    "        data = data.to(device)\n",
    "        z = encoder(data)\n",
    "        # Compute the user attribute encodings\n",
    "        attribute_encodings = co_encoder(dynamic_attribute, static_attribute)\n",
    "        node_embedding = seq2gauss(z, attribute_encodings)\n",
    "        node_embedding_list.append(node_embedding.cpu().detach())\n",
    "    node_embedding = node_embedding_list[0]\n",
    "    for i in node_embedding_list[1:]:\n",
    "        node_embedding = torch.concat((node_embedding, i), dim=0)\n",
    "    source_graph_feat = node_embedding[0:3881].to(device)\n",
    "    target_graph_feat = node_embedding[3881:].to(device)\n",
    "    source_views_city1 = mvgat(source_graph_input1, source_graph_feat)\n",
    "    source_views_city2 = mvgat(source_graph_input2, source_graph_feat)\n",
    "    target_views = mvgat(target_graph_input, target_graph_feat)\n",
    "    source_fused_emb1, source_embs = fusion(source_views_city1)  \n",
    "    source_fused_emb2, source_embs = fusion(source_views_city2) \n",
    "    \n",
    "    target_fused_emb, target_embs = fusion(target_views) \n",
    "    mmdloss = mmd_loss(source_fused_emb, target_fused_emb,sigma)\n",
    "    source_zone_embedding1, source_matrix1 = source_agg_graph1(source_fused_emb1)\n",
    "    source_zone_embedding2, source_matrix2 = source_agg_graph2(source_fused_emb2)\n",
    "    target_zone_embedding1, target_matrix = target_agg_graph(target_fused_emb)\n",
    "    source_fused_emb =torch.concat((source_fused_emb1, source_fused_emb2), dim=0)\n",
    "    entropy_loss = nn.CrossEntropyLoss()\n",
    "    entropy_loss = entropy_loss(source_matrix1, source_matrix1) + entropy_loss(source_matrix2, source_matrix2) + entropy_loss(target_matrix, target_matrix)\n",
    "    loss_global = mmdloss + 0.01 * entropy_loss\n",
    "\n",
    "    spt_task_data, spt_task_A, qry_task_data, qry_task_A = source_dataset.get_maml_task_batch(task_args['task_num'])\n",
    "    loss = model_STMAML.meta_train_revise(spt_task_data, spt_task_A, qry_task_data, qry_task_A)\n",
    "    source_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    source_optimizer.step()\n",
    "    end_time = time.time()\n",
    "    print(\"[Source Train] epoch #{}/{}: loss is {}, training time is {}\".format(epoch+1, source_epochs, loss.detach().cpu().numpy(), end_time-start_time))\n",
    "\n",
    "print(\"Source dataset meta-train finish.\")\n",
    "\n",
    "metric, output, label =  model_STMAML.finetuning(target_dataloader, test_dataloader, target_epochs, wd_ft, means, stds, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07136e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca27f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88354e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd2e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f8f16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # 读取CSV文件\n",
    "# # df_post = pd.read_csv('../../zz_relation_value.csv')\n",
    "# df_post = pd.read_csv('../../sh_relation_value.csv')\n",
    "# # 将dt列转换为datetime类型，以便进行分组\n",
    "# df_post['dt'] = pd.to_datetime(df_post['date'])\n",
    "# # 分组操作，每天构建一张图\n",
    "# source_graphs = []\n",
    "# for _, group in tqdm(df_post.groupby('date')):\n",
    "#     # 获取节点和边的数据\n",
    "#     src = torch.tensor(group['node1'].to_numpy())\n",
    "#     dst = torch.tensor(group['node2'].to_numpy())\n",
    "#     edge_data = torch.tensor(group['rv'].to_numpy())\n",
    "#     # 创建DGL图\n",
    "#     bj_g = dgl.graph((src, dst))\n",
    "#     # 添加边的特征\n",
    "#     bj_g.edata['rv'] = edge_data\n",
    "#     # 将图添加到图列表中\n",
    "#     source_graphs.append(bj_g)\n",
    "# # f = open('../../bj_time_series_update.pkl','rb')\n",
    "# f = open('../../sh_time_series_update.pkl','rb')\n",
    "\n",
    "# bj_time_series = pickle.load(f)\n",
    "# bj_time_series_list = []\n",
    "# for i in tqdm(np.array(bj_g.nodes())):\n",
    "#     time_series = bj_time_series[str(i)]\n",
    "#     bj_time_series_list.append(time_series)\n",
    "# bj_time_serie_np = np.array(bj_time_series_list)\n",
    "# # 读取CSV文件\n",
    "# # sh_post = pd.read_csv('../../sh_relation_value.csv')\n",
    "# sh_post = pd.read_csv('../../bj_relation_value.csv')\n",
    "# # 将dt列转换为datetime类型，以便进行分组\n",
    "# sh_post['dt'] = pd.to_datetime(sh_post['date'])\n",
    "# # 分组操作，每天构建一张图\n",
    "# target_graphs = []\n",
    "# for _, group in tqdm(sh_post.groupby('date')):\n",
    "#     # 获取节点和边的数据\n",
    "#     src = torch.tensor(group['node1'].to_numpy())\n",
    "#     dst = torch.tensor(group['node2'].to_numpy())\n",
    "#     edge_data = torch.tensor(group['rv'].to_numpy())\n",
    "#     # 创建DGL图\n",
    "#     sh_g = dgl.graph((src, dst))\n",
    "#     # 添加边的特征\n",
    "#     sh_g.edata['rv'] = edge_data\n",
    "#     # 将图添加到图列表中\n",
    "#     target_graphs.append(sh_g)\n",
    "# print(sh_g)\n",
    "# # f = open('../../sh_time_series_update.pkl','rb')\n",
    "# f = open('../../bj_time_series_update.pkl','rb')\n",
    "\n",
    "# sh_time_series = pickle.load(f)\n",
    "# sh_time_series_list = []\n",
    "# long_term_list = []\n",
    "# for i in tqdm(np.array(sh_g.nodes())):\n",
    "#     time_series = sh_time_series[str(i)]\n",
    "#     sh_time_series_list.append(time_series)\n",
    "# time_serie_np = np.array(sh_time_series_list)\n",
    "# # 后3881个数据是target部分的\n",
    "# time_series_list = []\n",
    "# for index in bj_time_series_list:\n",
    "#     time_series_list.append(index)\n",
    "# for index in sh_time_series_list:\n",
    "#     time_series_list.append(index)\n",
    "# time_series_np = np.array(time_series_list)\n",
    "# f = open('../../industry_l3_id.pkl','rb')\n",
    "# industry = pickle.load(f)\n",
    "# for index in range(len(industry)):\n",
    "#     industry[index] = int(industry[index])\n",
    "# # source_graphs\n",
    "# # df_peer = pd.read_csv('../../0420_bj_relation_peer_update_l3_area.csv')\n",
    "# df_peer = pd.read_csv('../../0422_sh_relation_peer_update_L3_area.csv')\n",
    "# # 获取节点和边的数据\n",
    "# src = torch.tensor(df_peer['node1'].to_numpy())\n",
    "# dst = torch.tensor(df_peer['node2'].to_numpy())\n",
    "# # edge_data = torch.tensor(df_peer['rv'].to_numpy())\n",
    "# # 创建DGL图\n",
    "# source_graph_peer = dgl.graph((src, dst))\n",
    "# # 添加边的特征\n",
    "# # source_graph_peer.edata['rv'] = edge_data\n",
    "# # target_graphs\n",
    "# # df_peer = pd.read_csv('../../0422_sh_relation_peer_update_L3_area.csv')\n",
    "# df_peer = pd.read_csv('../../0420_bj_relation_peer_update_l3_area.csv')\n",
    "# # 获取节点和边的数据\n",
    "# src = torch.tensor(df_peer['node1'].to_numpy())\n",
    "# dst = torch.tensor(df_peer['node2'].to_numpy())\n",
    "# # edge_data = torch.tensor(df_peer['rv'].to_numpy())\n",
    "# # 创建DGL图\n",
    "# target_graph_peer = dgl.graph((src, dst))\n",
    "# # 添加边的特征\n",
    "# # target_graph_peer.edata['rv'] = edge_data\n",
    "# # 读取CSV文件\n",
    "# # df_post = pd.read_csv('../../bj_relation_value.csv')\n",
    "# df_post = pd.read_csv('../../sh_relation_value.csv')\n",
    "# # 将dt列转换为datetime类型，以便进行分组\n",
    "# df_post['dt'] = pd.to_datetime(df_post['date'])\n",
    "# # 分组操作，每天构建一张图\n",
    "# source_graphs = []\n",
    "# for _, group in tqdm(df_post.groupby('date')):\n",
    "#     # 获取节点和边的数据\n",
    "#     src = torch.tensor(group['node1'].to_numpy())\n",
    "#     dst = torch.tensor(group['node2'].to_numpy())\n",
    "# #     edge_data = torch.tensor(group['rv'].to_numpy())\n",
    "#     # 创建DGL图\n",
    "#     g = dgl.graph((src, dst))\n",
    "#     # 添加边的特征\n",
    "# #     g.edata['rv'] = edge_data\n",
    "# #     g.ndata['feat'] = node_embedding.cpu()[0:12044]\n",
    "# #     g = dgl.add_self_loop(g)\n",
    "#     # 将图添加到图列表中\n",
    "#     source_graphs.append(g)\n",
    "# # 读取CSV文件\n",
    "# # sh_post = pd.read_csv('../../sh_relation_value.csv')\n",
    "# sh_post = pd.read_csv('../../bj_relation_value.csv')\n",
    "# # 将dt列转换为datetime类型，以便进行分组\n",
    "# sh_post['dt'] = pd.to_datetime(sh_post['date'])\n",
    "# # 分组操作，每天构建一张图\n",
    "# target_graphs = []\n",
    "# for _, group in tqdm(sh_post.groupby('date')):\n",
    "#     # 获取节点和边的数据\n",
    "#     src = torch.tensor(group['node1'].to_numpy())\n",
    "#     dst = torch.tensor(group['node2'].to_numpy())\n",
    "# #     edge_data = torch.tensor(group['rv'].to_numpy())\n",
    "#     # 创建DGL图\n",
    "#     sh_g = dgl.graph((src, dst))\n",
    "#     # 添加边的特征\n",
    "# #     sh_g.edata['rv'] = edge_data\n",
    "# #     sh_g.ndata['feat'] = node_embedding.cpu()[12044:]\n",
    "# #     sh_g = dgl.add_self_loop(sh_g)\n",
    "#     # 将图添加到图列表中\n",
    "#     target_graphs.append(sh_g)\n",
    "# print(sh_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe7953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d050eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc64dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58c374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346d229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
